{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scraping Reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Applications\\Anaconda\\lib\\site-packages\\sklearn\\cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Ronak\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Ronak\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\Ronak\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'a',\n",
       " 'about',\n",
       " 'above',\n",
       " 'after',\n",
       " 'again',\n",
       " 'against',\n",
       " 'ain',\n",
       " 'all',\n",
       " 'am',\n",
       " 'an',\n",
       " 'and',\n",
       " 'any',\n",
       " 'are',\n",
       " 'aren',\n",
       " \"aren't\",\n",
       " 'as',\n",
       " 'at',\n",
       " 'be',\n",
       " 'because',\n",
       " 'been',\n",
       " 'before',\n",
       " 'being',\n",
       " 'below',\n",
       " 'between',\n",
       " 'both',\n",
       " 'but',\n",
       " 'by',\n",
       " 'can',\n",
       " 'couldn',\n",
       " \"couldn't\",\n",
       " 'd',\n",
       " 'did',\n",
       " 'didn',\n",
       " \"didn't\",\n",
       " 'do',\n",
       " 'does',\n",
       " 'doesn',\n",
       " \"doesn't\",\n",
       " 'doing',\n",
       " 'don',\n",
       " \"don't\",\n",
       " 'down',\n",
       " 'during',\n",
       " 'each',\n",
       " 'few',\n",
       " 'for',\n",
       " 'from',\n",
       " 'further',\n",
       " 'had',\n",
       " 'hadn',\n",
       " \"hadn't\",\n",
       " 'has',\n",
       " 'hasn',\n",
       " \"hasn't\",\n",
       " 'have',\n",
       " 'haven',\n",
       " \"haven't\",\n",
       " 'having',\n",
       " 'he',\n",
       " 'her',\n",
       " 'here',\n",
       " 'hers',\n",
       " 'herself',\n",
       " 'him',\n",
       " 'himself',\n",
       " 'his',\n",
       " 'how',\n",
       " 'i',\n",
       " 'if',\n",
       " 'in',\n",
       " 'into',\n",
       " 'is',\n",
       " 'isn',\n",
       " \"isn't\",\n",
       " 'it',\n",
       " \"it's\",\n",
       " 'its',\n",
       " 'itself',\n",
       " 'just',\n",
       " 'll',\n",
       " 'm',\n",
       " 'ma',\n",
       " 'me',\n",
       " 'mightn',\n",
       " \"mightn't\",\n",
       " 'more',\n",
       " 'most',\n",
       " 'mustn',\n",
       " \"mustn't\",\n",
       " 'my',\n",
       " 'myself',\n",
       " 'needn',\n",
       " \"needn't\",\n",
       " 'no',\n",
       " 'nor',\n",
       " 'not',\n",
       " 'now',\n",
       " 'o',\n",
       " 'of',\n",
       " 'off',\n",
       " 'on',\n",
       " 'once',\n",
       " 'only',\n",
       " 'or',\n",
       " 'other',\n",
       " 'our',\n",
       " 'ours',\n",
       " 'ourselves',\n",
       " 'out',\n",
       " 'over',\n",
       " 'own',\n",
       " 're',\n",
       " 's',\n",
       " 'same',\n",
       " 'shan',\n",
       " \"shan't\",\n",
       " 'she',\n",
       " \"she's\",\n",
       " 'should',\n",
       " \"should've\",\n",
       " 'shouldn',\n",
       " \"shouldn't\",\n",
       " 'so',\n",
       " 'some',\n",
       " 'such',\n",
       " 't',\n",
       " 'than',\n",
       " 'that',\n",
       " \"that'll\",\n",
       " 'the',\n",
       " 'their',\n",
       " 'theirs',\n",
       " 'them',\n",
       " 'themselves',\n",
       " 'then',\n",
       " 'there',\n",
       " 'these',\n",
       " 'they',\n",
       " 'this',\n",
       " 'those',\n",
       " 'through',\n",
       " 'to',\n",
       " 'too',\n",
       " 'under',\n",
       " 'until',\n",
       " 'up',\n",
       " 've',\n",
       " 'very',\n",
       " 'was',\n",
       " 'wasn',\n",
       " \"wasn't\",\n",
       " 'we',\n",
       " 'were',\n",
       " 'weren',\n",
       " \"weren't\",\n",
       " 'what',\n",
       " 'when',\n",
       " 'where',\n",
       " 'which',\n",
       " 'while',\n",
       " 'who',\n",
       " 'whom',\n",
       " 'why',\n",
       " 'will',\n",
       " 'with',\n",
       " 'won',\n",
       " \"won't\",\n",
       " 'wouldn',\n",
       " \"wouldn't\",\n",
       " 'y',\n",
       " 'you',\n",
       " \"you'd\",\n",
       " \"you'll\",\n",
       " \"you're\",\n",
       " \"you've\",\n",
       " 'your',\n",
       " 'yours',\n",
       " 'yourself',\n",
       " 'yourselves'}"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Definitions and imports\n",
    "\n",
    "from lxml import html  \n",
    "import requests\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn import naive_bayes\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from textblob import TextBlob as tb\n",
    "\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Creating an empty dataframe for reviews of Amazon Echo Dot\n",
    "reviews_df = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Defining local browser's user agent string to avoid requests being blocked\n",
    "user_agent = 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/65.0.3325.181 Safari/537.36'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Creating a list of URL's that point to the first 1000 review pages for Apple Airpods\n",
    "\n",
    "url_list = []\n",
    "\n",
    "for i in range(1,1001):\n",
    "    url_list.append(\"https://www.amazon.com/Apple-MD827LL-EarPods-Remote-Mic/product-reviews/B0097BEG1C/ref=cm_cr_getr_d_paging_btm_prev_1?ie=UTF8&reviewerType=all_reviews&sortBy=recent&pageNumber={0}\".format(i))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Total number of URL's\n",
    "len(url_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Loop to fetch reviews from Amazon\n",
    "\n",
    "# Looping through all 1000 URL's\n",
    "for u in url_list:\n",
    "    amazon_url = u\n",
    "    \n",
    "    # Setting header to user agent string\n",
    "    headers = {'User-Agent': user_agent}\n",
    "    page = requests.get(amazon_url, headers = headers)\n",
    "    # Define parser\n",
    "    parser = html.fromstring(page.content)\n",
    "    \n",
    "    # All reviews are located in a div tag with class \"review\"\n",
    "    xpath_reviews = '//div[@data-hook=\"review\"]'\n",
    "    reviews = parser.xpath(xpath_reviews)\n",
    "    \n",
    "    # Within the review div, the following 2 items can be located\n",
    "    \n",
    "    # The rating is located in an i tag with class \"review-star-rating\"\n",
    "    #xpath_rating  = './/i[@data-hook=\"review-star-rating\"]//text()' \n",
    "    \n",
    "    # The body text of the review is located in a span tag with class \"review-body\"\n",
    "    xpath_body    = './/span[@data-hook=\"review-body\"]//text()'\n",
    "    \n",
    "    # Looping through each outer div tag and appending results to the dataframe\n",
    "    for review in reviews:\n",
    "        body    = review.xpath(xpath_body)\n",
    "\n",
    "        review_dict = {'body' : body}\n",
    "        \n",
    "        reviews_df = reviews_df.append(review_dict, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>body</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[Both daughters say their headphones still wor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[False advertisement, not an apple product.  T...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[I had apple earbuds to compare, and there was...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[I don’t recommend buying these. Literally it ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[they stop working after a month of use]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                body\n",
       "0  [Both daughters say their headphones still wor...\n",
       "1  [False advertisement, not an apple product.  T...\n",
       "2  [I had apple earbuds to compare, and there was...\n",
       "3  [I don’t recommend buying these. Literally it ...\n",
       "4           [they stop working after a month of use]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Dropping any null cells\n",
    "reviews_df.replace('', np.nan, inplace=True)\n",
    "reviews_df.dropna(inplace=True,axis = 0)\n",
    "\n",
    "reviews_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "body    10000\n",
       "dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Verifying review count\n",
    "reviews_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Each row is currently a list object due to some reviews having responses and thus creating a list of review body texts\n",
    "#We go around this by considering the main review and discarding the rest and the exporting to a csv\n",
    "import re\n",
    "reviews_df_text = pd.DataFrame()\n",
    "\n",
    "for i in reviews_df['body']:\n",
    "    if i:\n",
    "        text = i[0].strip()\n",
    "        \n",
    "        #Many reviews have emojis and special characters. This section defines hex code ranges and removes them.\n",
    "        emoji_pattern = re.compile(\"[\"\n",
    "            u\"\\U0001F600-\\U0001F926\"  # emoticons\n",
    "            u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "            u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "            u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "            u\"\\U0001FE0F-\\U0001Fe0F\"  # hearts\n",
    "            u\"\\U00002764-\\U0001Fe0F\"  # hearts\n",
    "            u\"\\U00002753\"             # question marks\n",
    "                               \"]+\", flags=re.UNICODE)\n",
    "        text2 = emoji_pattern.sub(r'', text) # no emoji\n",
    "            \n",
    "        text_dict = {'body' : text2}\n",
    "        \n",
    "        reviews_df_text = reviews_df_text.append(text_dict, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Exporting to csv\n",
    "reviews_df_text.to_csv(\"Final_Amazon_Reviews.csv\",encoding='utf8',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classifying sentiments for the reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Extracting data from csv since scraping changes dataset on every run.\n",
    "\n",
    "review_data = pd.read_csv(\"Final_Amazon_Reviews.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>body</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Both daughters say their headphones still work...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>False advertisement, not an apple product.  Th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I had apple earbuds to compare, and there was ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I don’t recommend buying these. Literally it h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>they stop working after a month of use</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                body\n",
       "0  Both daughters say their headphones still work...\n",
       "1  False advertisement, not an apple product.  Th...\n",
       "2  I had apple earbuds to compare, and there was ...\n",
       "3  I don’t recommend buying these. Literally it h...\n",
       "4             they stop working after a month of use"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "review_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I had apple earbuds to compare, and there was a noticable sound difference. These did not produce as clear a sound, and had problems dealing with bass. Weather or not these are knock-offs I don’t know. They could just be older. Either way, disappointed with the sound quality.'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Extracting one review as an example\n",
    "blob_ex = review_data['body'][2].strip()\n",
    "blob_ex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Creating a text blob object from the review\n",
    "test_blob = tb(blob_ex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WordList(['I', 'had', 'apple', 'earbuds', 'to', 'compare', 'and', 'there', 'was', 'a', 'noticable', 'sound', 'difference', 'These', 'did', 'not', 'produce', 'as', 'clear', 'a', 'sound', 'and', 'had', 'problems', 'dealing', 'with', 'bass', 'Weather', 'or', 'not', 'these', 'are', 'knock-offs', 'I', 'don', '’', 't', 'know', 'They', 'could', 'just', 'be', 'older', 'Either', 'way', 'disappointed', 'with', 'the', 'sound', 'quality'])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Listing the words in the review\n",
    "test_blob.words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('I', 'PRP'),\n",
       " ('had', 'VBD'),\n",
       " ('apple', 'NN'),\n",
       " ('earbuds', 'NN'),\n",
       " ('to', 'TO'),\n",
       " ('compare', 'VB'),\n",
       " ('and', 'CC'),\n",
       " ('there', 'RB'),\n",
       " ('was', 'VBD'),\n",
       " ('a', 'DT'),\n",
       " ('noticable', 'JJ'),\n",
       " ('sound', 'NN'),\n",
       " ('difference', 'NN'),\n",
       " ('These', 'DT'),\n",
       " ('did', 'VBD'),\n",
       " ('not', 'RB'),\n",
       " ('produce', 'VB'),\n",
       " ('as', 'IN'),\n",
       " ('clear', 'JJ'),\n",
       " ('a', 'DT'),\n",
       " ('sound', 'NN'),\n",
       " ('and', 'CC'),\n",
       " ('had', 'VBD'),\n",
       " ('problems', 'NNS'),\n",
       " ('dealing', 'VBG'),\n",
       " ('with', 'IN'),\n",
       " ('bass', 'NN'),\n",
       " ('Weather', 'PRP$'),\n",
       " ('or', 'CC'),\n",
       " ('not', 'RB'),\n",
       " ('these', 'DT'),\n",
       " ('are', 'VBP'),\n",
       " ('knock-offs', 'NNS'),\n",
       " ('I', 'PRP'),\n",
       " ('don', 'VBP'),\n",
       " ('’', 'JJ'),\n",
       " ('t', 'NN'),\n",
       " ('know', 'VBP'),\n",
       " ('They', 'PRP'),\n",
       " ('could', 'MD'),\n",
       " ('just', 'RB'),\n",
       " ('be', 'VB'),\n",
       " ('older', 'JJR'),\n",
       " ('Either', 'DT'),\n",
       " ('way', 'NN'),\n",
       " ('disappointed', 'VBN'),\n",
       " ('with', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('sound', 'NN'),\n",
       " ('quality', 'NN')]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Listing tags for each of the words in the review\n",
    "#For example, 'quality' is marked as a noun\n",
    "test_blob.tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sentiment(polarity=0.08095238095238096, subjectivity=0.4523809523809524)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Extracting the sentiment for the review. This returns 2 values\n",
    "# 1. Polarity: A range from -1 to 1 indicating sentiment where -1 is negative, 0 is neutral and 1 is positive\n",
    "# 2. Subjectivity: This returns a float between 0 and 1 where 0 is very objective and 1 is very subjective\n",
    "test_blob.sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Extracting the sentiment polarity into a variable\n",
    "sent_val = test_blob.sentiment.polarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.08095238095238096"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Verify sentiment value\n",
    "sent_val"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For the purposes of the analysis here, I have considered neutral values  top be positive and defined the following rule. \n",
    "\n",
    "##### if sent_val >= 0:\n",
    "#####    print(\"Positive\")\n",
    "##### else:\n",
    "#####    print(\"Negative\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Creating an empty dataframe for the review text and its respective sentiment\n",
    "sent_df = pd.DataFrame()\n",
    "\n",
    "for i in review_data['body']:\n",
    "    #Extract review text\n",
    "    text = i.strip()\n",
    "    \n",
    "    #Creating text blob\n",
    "    body_text = tb(text)\n",
    "    \n",
    "    #Extract sentiment polarity\n",
    "    sent_pol = body_text.sentiment.polarity\n",
    "    \n",
    "    if sent_pol >= 0:\n",
    "        sent_val = 1\n",
    "    else:\n",
    "        sent_val = 0\n",
    "        \n",
    "    comb_dict = {'review': text,\n",
    "                   'sentiment': sent_val}\n",
    "    #print(sent_val)\n",
    "    \n",
    "    sent_df = sent_df.append(comb_dict, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Both daughters say their headphones still work...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>False advertisement, not an apple product.  Th...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I had apple earbuds to compare, and there was ...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I don’t recommend buying these. Literally it h...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>they stop working after a month of use</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review  sentiment\n",
       "0  Both daughters say their headphones still work...        1.0\n",
       "1  False advertisement, not an apple product.  Th...        0.0\n",
       "2  I had apple earbuds to compare, and there was ...        1.0\n",
       "3  I don’t recommend buying these. Literally it h...        1.0\n",
       "4             they stop working after a month of use        1.0"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#A combined dataframe with the sentiment values for each review is created\n",
    "sent_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Exporting to csv to keep record\n",
    "sent_df.to_csv(header=True,path_or_buf=\"sentiment_one.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayesian Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Defining the stopset of english words\n",
    "#This defines a list of words that are inconsequential to sentiment analysis and can be removed from the data\n",
    "stopset = set(stopwords.words('english'))\n",
    "\n",
    "#Defining a TfidVectorizer to convert the raw text into a sparse matrix\n",
    "#This matrix essentially holds a frequency for each word and associates the words with either a positive or negative sentiment\n",
    "vectorizer = TfidfVectorizer(use_idf=True, lowercase=True, strip_accents='ascii', stop_words=stopset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Defining the predictor variables, i.e. the sentiment\n",
    "y = sent_df.sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Vectorize the reviews from the dataframe\n",
    "x = vectorizer.fit_transform(sent_df.review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9990,)\n"
     ]
    }
   ],
   "source": [
    "#This is the number of records \n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9990, 6216)\n"
     ]
    }
   ],
   "source": [
    "# This returns 2 values.\n",
    "# 1. Number of input records\n",
    "# 2. Number of unique words in the dataset\n",
    "print(x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Using sklearn to perform a train test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(x, y, train_size=0.8, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Defining a Naice Bayes classifier and fitting it to our train data\n",
    "clf = naive_bayes.MultinomialNB()\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.89980625927258018"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Using roc_auc_score to determin the accuracy of the classifier\n",
    "roc_auc_score(y_test, clf.predict_proba(X_test)[:,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating sample sentences to test the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Define and vectorise a positive sentence\n",
    "sample_array_pos = np.array([\"I enjoyed this product\"])\n",
    "sample_vector_pos = vectorizer.transform(sample_array_pos)\n",
    "\n",
    "#Define and vectorize a negatie sentence\n",
    "sample_array_neg = np.array([\"I hate it. It's useless and can't do anything\"])\n",
    "sample_vector_neg = vectorizer.transform(sample_array_neg)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 6216)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#This means that we are analysing this one sample based on evidence collected for over 7000 words.\n",
    "sample_vector_pos.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive\n"
     ]
    }
   ],
   "source": [
    "#Predict sentiment for the positive vector\n",
    "sentiment = clf.predict(sample_vector_pos)\n",
    "\n",
    "if sentiment == 1:\n",
    "    print(\"Positive\")\n",
    "else:\n",
    "    print(\"Negative\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Negative\n"
     ]
    }
   ],
   "source": [
    "#Predict sentiment for the negative vector\n",
    "sentiment = clf.predict(sample_vector_neg)\n",
    "\n",
    "if sentiment == 1:\n",
    "    print(\"Positive\")\n",
    "else:\n",
    "    print(\"Negative\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Conclusions:\n",
    "\n",
    "1. The dataset constantly fluctuates in sentiment based on what product reviews were scraped and when they were scraped.\n",
    "2. Most reviews on amazon seem to be positive. This makes our model biased and results in a few misclassifications.\n",
    "3. For the naive bayes classifier, the accuracy varies between 85% to 98% depending on the nature of the input data.\n",
    "4. In general, adding more data tends to increase the accuracy since the model is exposed to a larger amount of words."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
